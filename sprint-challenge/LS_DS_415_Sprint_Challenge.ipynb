{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset/challenge). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "*Successfully complete these all these objectives to earn a 2. There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "yelp = pd.read_json('./data/review_sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    tokens = []\n",
    "    for i in doc:\n",
    "        token = i.split()\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(yelp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEWARE!!!',\n",
       " 'FAKE,',\n",
       " 'FAKE,',\n",
       " 'FAKE....We',\n",
       " 'also',\n",
       " 'own',\n",
       " 'a',\n",
       " 'small',\n",
       " 'business',\n",
       " 'in',\n",
       " 'Los',\n",
       " 'Alamitos,',\n",
       " 'CA',\n",
       " 'and',\n",
       " 'received',\n",
       " 'what',\n",
       " 'looked',\n",
       " 'like',\n",
       " 'a',\n",
       " 'legitimate',\n",
       " 'bill',\n",
       " 'for',\n",
       " '$70',\n",
       " 'with',\n",
       " 'an',\n",
       " 'account',\n",
       " 'number',\n",
       " 'and',\n",
       " 'all.',\n",
       " 'I',\n",
       " 'called',\n",
       " 'the',\n",
       " 'phone',\n",
       " 'number',\n",
       " 'listed',\n",
       " '(866)',\n",
       " '273-7934.',\n",
       " 'The',\n",
       " 'wait',\n",
       " 'time',\n",
       " 'on',\n",
       " 'hold',\n",
       " 'said',\n",
       " '20',\n",
       " 'minutes',\n",
       " 'and',\n",
       " 'to',\n",
       " 'leave',\n",
       " 'a',\n",
       " 'message.',\n",
       " 'I',\n",
       " 'could',\n",
       " 'not',\n",
       " 'get',\n",
       " 'a',\n",
       " 'live',\n",
       " 'person',\n",
       " 'on',\n",
       " 'the',\n",
       " 'phone',\n",
       " 'no',\n",
       " 'matter',\n",
       " 'what',\n",
       " 'number',\n",
       " 'I',\n",
       " 'selected.',\n",
       " 'I',\n",
       " 'left',\n",
       " 'a',\n",
       " 'very',\n",
       " 'FIRM',\n",
       " 'message',\n",
       " 'that',\n",
       " 'I',\n",
       " 'would',\n",
       " 'be',\n",
       " 'contacting',\n",
       " 'the',\n",
       " 'BBB',\n",
       " 'and',\n",
       " 'my',\n",
       " 'attorney',\n",
       " 'regarding',\n",
       " 'their',\n",
       " 'company',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'scam',\n",
       " 'businesses.',\n",
       " 'This',\n",
       " 'has',\n",
       " 'to',\n",
       " 'be',\n",
       " 'illegal!!!!!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews\n",
    "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, it will probably be best to use a `NearestNeighbors` model for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "vect.fit(yelp['text'])\n",
    "dtm = vect.transform(yelp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>001695</th>\n",
       "      <th>007</th>\n",
       "      <th>00a</th>\n",
       "      <th>00am</th>\n",
       "      <th>00ish</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>011802</th>\n",
       "      <th>...</th>\n",
       "      <th>誰も乗車しなくても</th>\n",
       "      <th>豆腐花</th>\n",
       "      <th>質問にも丁寧に答えてくれましたし</th>\n",
       "      <th>車好きさんには</th>\n",
       "      <th>這是一個不錯的選擇</th>\n",
       "      <th>運転しない</th>\n",
       "      <th>運転中も英語で指導があります</th>\n",
       "      <th>食べ物はうまい</th>\n",
       "      <th>餐後點了甜點</th>\n",
       "      <th>３時間後の便</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  001695  007  00a  00am  00ish  00pm   01  011802  ...  誰も乗車しなくても  \\\n",
       "0  0.0  0.0     0.0  0.0  0.0   0.0    0.0   0.0  0.0     0.0  ...        0.0   \n",
       "1  0.0  0.0     0.0  0.0  0.0   0.0    0.0   0.0  0.0     0.0  ...        0.0   \n",
       "2  0.0  0.0     0.0  0.0  0.0   0.0    0.0   0.0  0.0     0.0  ...        0.0   \n",
       "3  0.0  0.0     0.0  0.0  0.0   0.0    0.0   0.0  0.0     0.0  ...        0.0   \n",
       "4  0.0  0.0     0.0  0.0  0.0   0.0    0.0   0.0  0.0     0.0  ...        0.0   \n",
       "\n",
       "   豆腐花  質問にも丁寧に答えてくれましたし  車好きさんには  這是一個不錯的選擇  運転しない  運転中も英語で指導があります  食べ物はうまい  \\\n",
       "0  0.0               0.0      0.0        0.0    0.0             0.0      0.0   \n",
       "1  0.0               0.0      0.0        0.0    0.0             0.0      0.0   \n",
       "2  0.0               0.0      0.0        0.0    0.0             0.0      0.0   \n",
       "3  0.0               0.0      0.0        0.0    0.0             0.0      0.0   \n",
       "4  0.0               0.0      0.0        0.0    0.0             0.0      0.0   \n",
       "\n",
       "   餐後點了甜點  ３時間後の便  \n",
       "0     0.0     0.0  \n",
       "1     0.0     0.0  \n",
       "2     0.0     0.0  \n",
       "3     0.0     0.0  \n",
       "4     0.0     0.0  \n",
       "\n",
       "[5 rows x 27289 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = yelp['text']\n",
    "y = yelp['stars']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NearestNeighbors(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvect = TfidfVectorizer(stop_words='english')\n",
    "tvect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = tvect.transform(X_train)\n",
    "X_test_vect = tvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.kneighbors(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = 'Man this product sucked, 0 stars'\n",
    "maybe = tvect.transform([review])\n",
    "recs = nn.kneighbors(maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3329    I absolutely hate this gym. I had a membership...\n",
       "7083    Both of my kids are students at Liberty prep. ...\n",
       "6419    We have been here a couple of times for my wif...\n",
       "6820    **MARKHAM location review \\n**Markham location...\n",
       "305     This store is did not have the Reese's peanut ...\n",
       "1089    Sensi has wonderful seafood, great presentatio...\n",
       "3454    Had chicken biryani, chicken tikka and ras mal...\n",
       "5584    One of the best places for breakfast in town. ...\n",
       "585     Edo is excellent!  My fiance's boss took us ou...\n",
       "7027    My daughter transferred here from another gym ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.iloc[recs[1][0]]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a piepline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier. Use that pipeline to estimate a model to predict `stars`. Use the Pipeline to predict a star rating for your fake review from Part 2. \n",
    "2. Tune the entire pipeline with a GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "pipe = Pipeline([('vect',tvect),('clf',model)])\n",
    "\n",
    "params_grid = {\n",
    "    \"vect__min_df\": (0.02, 0.05),\n",
    "    \"vect__max_df\": (0.75, 1.0),\n",
    "    \"vect__max_features\": (500, 1000),\n",
    "    \"clf__n_estimators\": (5, 10),\n",
    "    \"clf__max_depth\": (15, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patte...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict([review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=pipe, param_grid=params_grid, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   38.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words...\n",
       "                                                               n_estimators=10,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (15, 20),\n",
       "                         'clf__n_estimators': (5, 10),\n",
       "                         'vect__max_df': (0.75, 1.0),\n",
       "                         'vect__max_features': (500, 1000),\n",
       "                         'vect__min_df': (0.02, 0.05)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict([review])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "Let's find out what those yelp reviews are saying! :D\n",
    "\n",
    "1. Estimate a LDA topic model of the review text\n",
    "2. Create 1-2 visualizations of the results\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import re\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = yelp['text'].astype(str).apply(lambda x:x.split())\n",
    "id2word = corpora.Dictionary(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(t) for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   random_state=723812,\n",
    "                   num_topics = 5,\n",
    "                   passes=10,\n",
    "                   workers=4\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"de\" + 0.003*\"et\" + 0.003*\"la\" + 0.003*\"à\" + 0.002*\"le\" + 0.002*\"un\" + 0.002*\"a\" + 0.002*\"&\" + 0.002*\"les\" + 0.001*\"en\"'),\n",
       " (1,\n",
       "  '0.003*\"you\" + 0.003*\"to\" + 0.002*\"the\" + 0.002*\"and\" + 0.002*\"is\" + 0.002*\"they\" + 0.002*\"your\" + 0.002*\"are\" + 0.001*\"will\" + 0.001*\"in\"'),\n",
       " (2,\n",
       "  '0.046*\"the\" + 0.027*\"and\" + 0.027*\"a\" + 0.024*\"to\" + 0.019*\"I\" + 0.018*\"of\" + 0.016*\"was\" + 0.014*\"is\" + 0.013*\"in\" + 0.012*\"for\"'),\n",
       " (3,\n",
       "  '0.038*\"and\" + 0.037*\"the\" + 0.031*\"I\" + 0.025*\"to\" + 0.023*\"a\" + 0.018*\"was\" + 0.012*\"of\" + 0.011*\"for\" + 0.011*\"my\" + 0.009*\"is\"'),\n",
       " (4,\n",
       "  '0.030*\"and\" + 0.022*\"the\" + 0.018*\"a\" + 0.015*\"is\" + 0.012*\"The\" + 0.011*\"I\" + 0.009*\"to\" + 0.009*\"of\" + 0.008*\"was\" + 0.008*\"are\"')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de et la\n",
      "\n",
      "\n",
      "you to the\n",
      "\n",
      "\n",
      "the and a\n",
      "\n",
      "\n",
      "and the I\n",
      "\n",
      "\n",
      "and the a\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]\n",
    "topics = [' '.join(t[0:3]) for t in words]\n",
    "for t in topics: \n",
    "    print(t)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1545229129983620569687705908\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1545229129983620569687705908_data = {\"mdsDat\": {\"x\": [0.1803864840948966, 0.17515683392914386, 0.05870455354355171, -0.23447215205702163, -0.17977571951057067], \"y\": [0.0076626405670958495, -0.0010543680196030167, -0.022295282247068067, -0.05359437321604113, 0.06928138291561634], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [52.913330078125, 42.75678253173828, 3.1980581283569336, 0.6541979908943176, 0.47763049602508545]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [36830.0, 44823.0, 26987.0, 12795.0, 9106.0, 26768.0, 15669.0, 5277.0, 28246.0, 11603.0, 12308.0, 6212.0, 6852.0, 8866.0, 18627.0, 3138.0, 8517.0, 2548.0, 2498.0, 3563.0, 6353.0, 2244.0, 5187.0, 2379.0, 4487.0, 4186.0, 3816.0, 2683.0, 7094.0, 2116.0, 141.5306854248047, 51.06355667114258, 44.46352005004883, 45.00409698486328, 44.45792770385742, 57.262420654296875, 33.5576171875, 46.82219314575195, 38.660221099853516, 134.18087768554688, 31.340845108032227, 27.927873611450195, 113.02497100830078, 28.15130615234375, 27.841279983520508, 42.76653289794922, 33.05775451660156, 24.889450073242188, 25.211885452270508, 23.116044998168945, 42.73464584350586, 23.61548614501953, 33.83212661743164, 27.032167434692383, 22.563154220581055, 21.759429931640625, 22.537456512451172, 21.493480682373047, 20.990304946899414, 21.99370002746582, 245.6007080078125, 175.8264923095703, 59.12778091430664, 28.011707305908203, 33.27622604370117, 151.45147705078125, 279.7201843261719, 29.50630760192871, 1443.3389892578125, 667.4825439453125, 83.01184844970703, 50.74726104736328, 48.83625793457031, 835.2885131835938, 50.999244689941406, 1012.22119140625, 6415.59912109375, 182.7408905029297, 165.49002075195312, 62.3186149597168, 2723.9560546875, 402.22784423828125, 18532.001953125, 470.8112487792969, 22678.369140625, 329.62603759765625, 3881.26611328125, 698.7643432617188, 356.3296203613281, 384.1123962402344, 10811.9404296875, 444.9627685546875, 5448.31103515625, 14696.5, 2533.73876953125, 21809.638671875, 13550.603515625, 1220.9522705078125, 4057.07470703125, 6473.2890625, 1287.2003173828125, 1551.01513671875, 1570.280517578125, 4752.3818359375, 1274.604736328125, 4385.70068359375, 3427.289306640625, 4575.4140625, 3671.558837890625, 2604.772216796875, 3671.00341796875, 6938.02197265625, 3264.2490234375, 5609.505859375, 5088.501953125, 2948.580810546875, 2910.135009765625, 2384.84375, 2568.715576171875, 2663.184814453125, 2999.645263671875, 42.1302490234375, 29.15612030029297, 28.35802459716797, 38.41473388671875, 30.63976287841797, 39.84409713745117, 26.95559310913086, 36.9469108581543, 31.88593101501465, 22.017061233520508, 24.338830947875977, 22.50747299194336, 20.445491790771484, 31.509763717651367, 20.42374038696289, 20.422828674316406, 27.606843948364258, 21.665184020996094, 19.874597549438477, 18.074989318847656, 19.882566452026367, 19.864158630371094, 20.6488037109375, 17.836326599121094, 18.590723037719727, 17.039594650268555, 17.795236587524414, 18.556528091430664, 20.60629653930664, 22.399869918823242, 24.956119537353516, 34.89128494262695, 22.397165298461914, 275.0160217285156, 31.797060012817383, 32.92363357543945, 70.32575225830078, 75.15599060058594, 84.91233825683594, 33.57872772216797, 36.84506607055664, 110.33573150634766, 29.851247787475586, 46.28606414794922, 530.31396484375, 52.27463150024414, 58.27613830566406, 239.2787322998047, 112.94746398925781, 127.939697265625, 74.34986114501953, 22219.505859375, 8386.314453125, 6262.63623046875, 6643.771484375, 12781.3193359375, 133.85134887695312, 3730.259521484375, 290.4233093261719, 368.4886474609375, 11711.814453125, 4499.2392578125, 1565.7989501953125, 4084.492919921875, 5569.40966796875, 2665.7783203125, 2780.54296875, 1169.8856201171875, 4095.429443359375, 1462.2122802734375, 7513.11181640625, 3295.5087890625, 3249.773681640625, 13071.935546875, 1238.2669677734375, 2686.627197265625, 2480.375244140625, 1751.46826171875, 2610.027099609375, 2845.065673828125, 1552.376708984375, 9318.560546875, 2703.574462890625, 1575.972900390625, 2740.173095703125, 1908.4964599609375, 3166.001708984375, 1966.0911865234375, 1905.3675537109375, 1651.3941650390625, 1964.31787109375, 6.195703506469727, 6.9700493812561035, 5.774988651275635, 5.221099376678467, 4.686713695526123, 4.682318210601807, 4.919492244720459, 4.210527420043945, 3.9566264152526855, 3.7109200954437256, 4.71586799621582, 3.7067487239837646, 3.915044069290161, 3.436786413192749, 3.6809027194976807, 3.4292471408843994, 3.429227590560913, 3.40909481048584, 3.4047420024871826, 3.4000370502471924, 3.159773111343384, 3.158416986465454, 3.158521890640259, 3.157958984375, 3.1569554805755615, 3.1579179763793945, 3.155005931854248, 3.156663417816162, 3.155910015106201, 3.1540701389312744, 16.538692474365234, 5.108122825622559, 9.497514724731445, 4.437680244445801, 20.765323638916016, 5.9026312828063965, 7.802333831787109, 28.110876083374023, 12.475839614868164, 40.59404373168945, 8.596670150756836, 25.837543487548828, 1064.770263671875, 431.61004638671875, 523.140869140625, 12.952005386352539, 283.5425109863281, 638.1284790039062, 156.4536895751953, 59.39754104614258, 70.00521087646484, 151.51309204101562, 774.918212890625, 239.36996459960938, 163.11912536621094, 22.746723175048828, 339.55633544921875, 247.7892303466797, 75.80928802490234, 254.0706024169922, 384.8111572265625, 135.28506469726562, 299.0376892089844, 234.9043731689453, 340.1331481933594, 110.1483383178711, 65.35468292236328, 130.0323944091797, 134.0547637939453, 133.7758331298828, 110.8970718383789, 74.39633178710938, 125.10955810546875, 107.77230834960938, 117.75772857666016, 131.1706085205078, 122.23939514160156, 104.69847869873047, 105.03832244873047, 24.88445281982422, 18.770610809326172, 14.2186918258667, 11.696135520935059, 13.327604293823242, 10.005891799926758, 8.72152328491211, 8.869938850402832, 8.955238342285156, 8.251479148864746, 7.131827354431152, 10.520587921142578, 5.56134557723999, 5.279494762420654, 5.004648685455322, 5.003889083862305, 4.904057025909424, 7.108051776885986, 4.622227668762207, 4.533688545227051, 4.436910152435303, 4.1696577072143555, 3.8797476291656494, 3.7876245975494385, 3.4169516563415527, 3.42478609085083, 3.32767391204834, 3.141456365585327, 3.286275863647461, 2.6716272830963135, 35.947486877441406, 7.951815605163574, 20.200502395629883, 5.878481388092041, 10.27829360961914, 7.128878116607666, 11.897008895874023, 12.222108840942383, 9.797635078430176, 6.614566326141357, 6.993548393249512, 5.553989887237549, 5.5006537437438965, 5.600331783294678, 5.557888031005859, 5.4037346839904785, 4.84088134765625, 3.0460386276245117, 2.6918909549713135, 2.4249985218048096, 2.296940803527832, 2.2933695316314697, 2.2944939136505127, 2.289264440536499, 3.3341033458709717, 1.5483149290084839, 1.5486738681793213, 1.545249104499817, 1.5445823669433594, 1.5427050590515137, 1.6583352088928223, 1.543122410774231, 1.7815662622451782, 1.0653945207595825, 1.0653562545776367, 1.0585845708847046, 1.05764639377594, 1.0090564489364624, 0.9353793859481812, 0.9352641701698303, 0.9351786971092224, 0.9351820349693298, 0.9333885312080383, 0.9319468140602112, 0.9346269965171814, 0.9327358603477478, 2.2583961486816406, 5.015084743499756, 4.953508377075195, 1.8818422555923462, 1.0121384859085083, 1.0118802785873413, 1.0159791707992554, 1.011538028717041, 2.986189842224121, 3.63010835647583, 2.094223976135254, 3.1343271732330322, 2.2964284420013428, 2.7318429946899414, 7.327532768249512, 15.579229354858398, 5.537052631378174, 9.645963668823242, 6.900661945343018, 15.165764808654785, 10.294961929321289, 7.993313789367676, 11.612321853637695, 5.059317111968994, 13.348533630371094, 12.545683860778809, 8.02636432647705, 4.7570695877075195, 4.854423999786377, 7.638026237487793, 4.526090145111084, 5.534743785858154, 4.436137676239014, 4.966964244842529, 6.387656211853027, 4.9221978187561035, 5.216257572174072, 4.042932033538818, 5.267945766448975, 4.680927753448486, 4.5700273513793945, 4.33374547958374, 4.746469020843506], \"Term\": [\"and\", \"the\", \"a\", \"is\", \"The\", \"to\", \"of\", \"are\", \"I\", \"in\", \"for\", \"this\", \"you\", \"with\", \"was\", \"food\", \"my\", \"great\", \"here\", \"place\", \"they\", \"your\", \"at\", \"will\", \"be\", \"as\", \"very\", \"good\", \"on\", \"service\", \"salon\", \"haircut\", \"appointment.\", \"dental\", \"tires\", \"polish\", \"thorough\", \"stylist\", \"fingers\", \"nails\", \"nails.\", \"plumbing\", \"gel\", \"welcoming.\", \"pepperoni\", \"questions.\", \"auto\", \"Mary\", \"understanding\", \"install\", \"manicure\", \"emailed\", \"services.\", \"Benedict\", \"repair.\", \"balloons\", \"lash\", \"helpful!\", \"Josh\", \"funny,\", \"appointment\", \"nail\", \"tire\", \"stars)\", \"Buffalo\", \"Dr.\", \"hair\", \"bf\", \"she\", \"She\", \"color\", \"dealership\", \"scheduled\", \"i\", \"experience!\", \"her\", \"my\", \",\", \"professional\", \"professional.\", \"me\", \"done\", \"I\", \"called\", \"and\", \"highly\", \"had\", \"He\", \"sweet\", \"car\", \"was\", \"him\", \"with\", \"to\", \"very\", \"the\", \"a\", \"he\", \"have\", \"for\", \"My\", \"will\", \"time\", \"it\", \"got\", \"that\", \"they\", \"The\", \"but\", \"so\", \"on\", \"of\", \"this\", \"is\", \"in\", \"were\", \"not\", \"be\", \"at\", \"we\", \"you\", \"hotels\", \"Mandalay\", \"museum\", \"MGM\", \"hotel,\", \"sleep\", \"smoking\", \"suite\", \"beds\", \"Dunkin\", \"Tower\", \"elevator\", \"cha\", \"meatballs\", \"park.\", \"opposite\", \"Downtown\", \"shuttle\", \"shelf\", \"Momofuku\", \"signage\", \"plays\", \"Bay\", \"Fremont\", \"rooms.\", \"climbing\", \"district\", \"laundry\", \"LV\", \"couch\", \"OK,\", \"compare\", \"public\", \"hotel\", \"What's\", \"sandwiches.\", \"park\", \"movie\", \"casino\", \"restaurants,\", \"resort\", \"staying\", \"stage\", \"city.\", \"room\", \"bus\", \"show.\", \"stay\", \"room.\", \"rooms\", \"mall\", \"the\", \"of\", \"in\", \"is\", \"a\", \"strip\", \"you\", \"meat\", \"quite\", \"to\", \"it\", \"there\", \"that\", \"for\", \"are\", \"we\", \"It\", \"The\", \"if\", \"was\", \"on\", \"but\", \"and\", \"your\", \"not\", \"at\", \"We\", \"were\", \"they\", \"from\", \"I\", \"this\", \"like\", \"have\", \"as\", \"with\", \"be\", \"so\", \"place\", \"my\", \"Bady\", \"Jeremy\", \"talent\", \"Sardine\", \"44\", \"commands\", \"Lopez\", \"basil.\", \"socializing\", \"tom\", \"Middle\", \"Northern\", \"Pastries\", \"airbrush\", \"Solon\", \"tiki\", \"tidy.\", \"Anton\", \"steal.\", \"omelet,\", \"Kabab\", \"grooming,\", \"400sqft\", \"deftly\", \"Caramelo\", \"Miku\", \"owing\", \"Conservatory\", \"Lahore\", \"Iwashi\", \"Huge\", \"Turkish\", \"Lovely\", \"Sammie\", \"pad\", \"always.\", \"chowder\", \"Indian\", \"clam\", \"Thai\", \"MUST\", \"Excellent\", \"and\", \"The\", \"is\", \"Delicious\", \"are\", \"a\", \"here\", \"Very\", \"Great\", \"great\", \"the\", \"this\", \"food\", \"Highly\", \"of\", \"with\", \"staff\", \"for\", \"I\", \"place\", \"was\", \"in\", \"to\", \"good\", \"chicken\", \"as\", \"be\", \"at\", \"We\", \"always\", \"were\", \"very\", \"we\", \"my\", \"on\", \"so\", \"you\", \"et\", \"\\u00e0\", \"le\", \"les\", \"un\", \"des\", \"une\", \"pas\", \"est\", \"tr\\u00e8s\", \"sont\", \"en\", \"mais\", \"ce\", \"je\", \"vous\", \"avec\", \"y\", \"Un\", \"qui\", \"dans\", \"\\u00e9tait\", \"bi\\u00e8res\", \"ou\", \"Nous\", \"ne\", \"j'ai\", \"sur\", \"Capitol\", \"pris\", \"de\", \"au\", \"la\", \"que\", \"pour\", \"Le\", \"&\", \"a\", \"in\", \"Great\", \"is\", \"!\", \"amazing\", \"the\", \"I\", \"for\", \"yuk\", \"Glo\", \"Killer\", \"Schwartz's\", \"Singapore\", \"Keri\", \"Schwarts'\", \"keratin\", \"Kia\", \"Chief!\", \"reef\", \"Suzanne\", \"Sundays,\", \"Bim\", \"Main.\", \"Hobby\", \"holiday.\", \"tar,\", \"tar\", \"bind\", \"agedashi\", \"Yuk!\", \"Wonderful,\", \"n'ai\", \"chaleureux\", \"L'ambiance\", \"price!!!\", \"COMPANY\", \"Guaranteed!\", \"BEST!\", \"Grace\", \"tan\", \"blow\", \"quick!\", \"4:\", \"3:\", \"cutter\", \"5:\", \"Studio\", \"spray\", \"poker\", \"Taiwanese\", \"Ray\", \"Ramen\", \"Great\", \"you\", \"hair\", \"your\", \"recommend\", \"to\", \"they\", \"will\", \"is\", \"ice\", \"the\", \"and\", \"are\", \"use\", \"service.\", \"in\", \"cream\", \"service\", \"highly\", \"I've\", \"for\", \"if\", \"my\", \"car\", \"I\", \"have\", \"not\", \"can\", \"a\"], \"Total\": [36830.0, 44823.0, 26987.0, 12795.0, 9106.0, 26768.0, 15669.0, 5277.0, 28246.0, 11603.0, 12308.0, 6212.0, 6852.0, 8866.0, 18627.0, 3138.0, 8517.0, 2548.0, 2498.0, 3563.0, 6353.0, 2244.0, 5187.0, 2379.0, 4487.0, 4186.0, 3816.0, 2683.0, 7094.0, 2116.0, 142.68804931640625, 51.59943389892578, 44.952091217041016, 45.50331497192383, 44.95603561401367, 57.94804382324219, 34.000282287597656, 47.518821716308594, 39.24838638305664, 136.2582550048828, 31.832256317138672, 28.37506675720215, 114.84366607666016, 28.634544372558594, 28.335500717163086, 43.55670166015625, 33.68075942993164, 25.36467933654785, 25.699777603149414, 23.565961837768555, 43.569976806640625, 24.07862091064453, 34.496498107910156, 27.563688278198242, 23.010448455810547, 22.197790145874023, 22.992984771728516, 21.934236526489258, 21.426469802856445, 22.451974868774414, 251.7932891845703, 179.88375854492188, 60.589324951171875, 28.59686279296875, 34.03792190551758, 157.54637145996094, 297.122314453125, 30.207544326782227, 1636.46728515625, 743.549072265625, 86.88087463378906, 52.642730712890625, 50.63465118408203, 962.07861328125, 53.0234489440918, 1215.5152587890625, 8517.6826171875, 202.8938751220703, 183.34451293945312, 65.61701965332031, 3546.155029296875, 471.38800048828125, 28246.19921875, 567.6256103515625, 36830.953125, 391.4124450683594, 5694.47705078125, 889.2548828125, 430.4923095703125, 467.7962951660156, 18627.544921875, 561.4563598632812, 8866.9677734375, 26768.9453125, 3816.996826171875, 44823.01171875, 26987.01953125, 1758.8575439453125, 6900.3046875, 12308.560546875, 1885.209716796875, 2379.255126953125, 2459.3271484375, 9340.53125, 1949.8472900390625, 8540.796875, 6353.22998046875, 9106.625, 7020.53076171875, 4616.830078125, 7094.5595703125, 15669.3642578125, 6212.40185546875, 12795.0234375, 11603.478515625, 5684.74072265625, 5685.07080078125, 4487.04248046875, 5187.71337890625, 5563.08154296875, 6852.6318359375, 42.59963607788086, 29.616439819335938, 28.82741355895996, 39.13359451293945, 31.219846725463867, 40.608909606933594, 27.484580993652344, 37.690032958984375, 32.5278434753418, 22.470943450927734, 24.85812759399414, 22.989971160888672, 20.88868522644043, 32.21918487548828, 20.89409065246582, 20.89665985107422, 28.26129722595215, 22.185117721557617, 20.356040954589844, 18.51476287841797, 20.374374389648438, 20.35858726501465, 21.166088104248047, 18.283226013183594, 19.057321548461914, 17.477174758911133, 18.255643844604492, 19.04021644592285, 21.148733139038086, 22.993759155273438, 25.641210556030273, 36.0033073425293, 23.01790428161621, 291.6940612792969, 32.89525604248047, 34.091392517089844, 74.20356750488281, 79.69457244873047, 90.5079345703125, 34.915653228759766, 38.449520111083984, 120.34929656982422, 30.958158493041992, 49.132041931152344, 664.6619873046875, 56.57585906982422, 63.68053436279297, 297.9742126464844, 131.9741973876953, 152.16993713378906, 84.48432922363281, 44823.01171875, 15669.3642578125, 11603.478515625, 12795.0234375, 26987.01953125, 162.60247802734375, 6852.6318359375, 394.1033935546875, 516.969482421875, 26768.9453125, 9340.53125, 2812.013916015625, 8540.796875, 12308.560546875, 5277.72998046875, 5563.08154296875, 2082.919189453125, 9106.625, 2714.8798828125, 18627.544921875, 7094.5595703125, 7020.53076171875, 36830.953125, 2244.57861328125, 5685.07080078125, 5187.71337890625, 3459.736328125, 5684.74072265625, 6353.22998046875, 3039.573974609375, 28246.19921875, 6212.40185546875, 3148.521484375, 6900.3046875, 4186.625, 8866.9677734375, 4487.04248046875, 4616.830078125, 3563.279052734375, 8517.6826171875, 6.754092693328857, 7.615161418914795, 6.33665657043457, 5.779757499694824, 5.218010902404785, 5.218416690826416, 5.487274646759033, 4.8069071769714355, 4.526675701141357, 4.249327659606934, 5.400301933288574, 4.24616813659668, 4.496976852416992, 3.966017723083496, 4.250769138336182, 3.9683523178100586, 3.973428964614868, 3.9517996311187744, 3.961867332458496, 3.965273857116699, 3.6869285106658936, 3.687612295150757, 3.688413143157959, 3.6883034706115723, 3.687473773956299, 3.688915967941284, 3.6863949298858643, 3.689467430114746, 3.689600944519043, 3.6876027584075928, 20.94029426574707, 6.13996696472168, 12.419248580932617, 5.426723957061768, 42.291969299316406, 8.360918045043945, 12.122902870178223, 69.50123596191406, 24.87445640563965, 131.52951049804688, 15.877273559570312, 84.81290435791016, 36830.953125, 9106.625, 12795.0234375, 33.16203689575195, 5277.72998046875, 26987.01953125, 2498.132568359375, 474.8193359375, 644.5497436523438, 2548.413818359375, 44823.01171875, 6212.40185546875, 3138.47021484375, 95.17443084716797, 15669.3642578125, 8866.9677734375, 1052.483154296875, 12308.560546875, 28246.19921875, 3563.279052734375, 18627.544921875, 11603.478515625, 26768.9453125, 2683.886962890625, 916.4019165039062, 4186.625, 4487.04248046875, 5187.71337890625, 3459.736328125, 1284.0517578125, 5684.74072265625, 3816.996826171875, 5563.08154296875, 8517.6826171875, 7094.5595703125, 4616.830078125, 6852.6318359375, 25.537050247192383, 19.35345458984375, 14.795580863952637, 12.272852897644043, 14.02315902709961, 10.609817504882812, 9.29587173461914, 9.474472999572754, 9.566207885742188, 8.822739601135254, 7.705509185791016, 11.590592384338379, 6.134839057922363, 5.848405361175537, 5.572838306427002, 5.572600841522217, 5.474096298217773, 7.971588134765625, 5.190197944641113, 5.101821422576904, 5.003941535949707, 4.7373433113098145, 4.4423370361328125, 4.355648517608643, 3.9806454181671143, 3.9907662868499756, 3.8932244777679443, 3.7059152126312256, 3.9028100967407227, 3.234736680984497, 70.31208801269531, 12.366171836853027, 48.14208984375, 9.444438934326172, 22.646167755126953, 20.61188507080078, 934.857666015625, 26987.01953125, 11603.478515625, 644.5497436523438, 12795.0234375, 150.3893280029297, 579.8419189453125, 44823.01171875, 28246.19921875, 12308.560546875, 5.421935081481934, 3.6337385177612305, 3.31274151802063, 3.0316109657287598, 2.881783962249756, 2.883419990539551, 2.8869974613189697, 2.9031810760498047, 4.312878608703613, 2.130596160888672, 2.132472515106201, 2.1339282989501953, 2.137585163116455, 2.1381592750549316, 2.300475597381592, 2.1419291496276855, 2.4872665405273438, 1.6546289920806885, 1.654745101928711, 1.6591830253601074, 1.6636232137680054, 1.5899360179901123, 1.5172384977340698, 1.5181984901428223, 1.5181034803390503, 1.5181334018707275, 1.5168051719665527, 1.5160961151123047, 1.5211879014968872, 1.5186537504196167, 4.506370544433594, 16.16136932373047, 27.284954071044922, 5.250451564788818, 1.767082691192627, 1.7676910161972046, 1.7842341661453247, 1.768979549407959, 16.48076629638672, 26.198261260986328, 8.68930721282959, 22.906511306762695, 12.135334014892578, 19.27260971069336, 644.5497436523438, 6852.6318359375, 297.122314453125, 2244.57861328125, 1005.3468017578125, 26768.9453125, 6353.22998046875, 2379.255126953125, 12795.0234375, 382.3443298339844, 44823.01171875, 36830.953125, 5277.72998046875, 430.8172912597656, 521.994384765625, 11603.478515625, 385.9311828613281, 2116.138427734375, 391.4124450683594, 1421.40283203125, 12308.560546875, 2714.8798828125, 8517.6826171875, 467.7962951660156, 28246.19921875, 6900.3046875, 5685.07080078125, 2098.537109375, 26987.01953125], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6284000277519226, 0.6261000037193298, 0.6255999803543091, 0.6255000233650208, 0.6254000067710876, 0.6245999932289124, 0.6233999729156494, 0.6216999888420105, 0.621399998664856, 0.6212000250816345, 0.6209999918937683, 0.6205999851226807, 0.6205999851226807, 0.6194999814033508, 0.6189000010490417, 0.6182000041007996, 0.6177999973297119, 0.6176000237464905, 0.6172999739646912, 0.6172000169754028, 0.6172000169754028, 0.6171000003814697, 0.6171000003814697, 0.6169999837875366, 0.6169000267982483, 0.616599977016449, 0.6165000200271606, 0.6161999702453613, 0.6158999800682068, 0.6158999800682068, 0.6115999817848206, 0.6136999726295471, 0.6121000051498413, 0.6158000230789185, 0.6139000058174133, 0.597100019454956, 0.576200008392334, 0.6129999756813049, 0.5109000205993652, 0.5285999774932861, 0.5910000205039978, 0.5997999906539917, 0.6003999710083008, 0.4952000081539154, 0.597599983215332, 0.45350000262260437, 0.3531000018119812, 0.5318999886512756, 0.5340999960899353, 0.5849000215530396, 0.3727000057697296, 0.4778999984264374, 0.2151000052690506, 0.4494999945163727, 0.15160000324249268, 0.46470001339912415, 0.2531999945640564, 0.3953999876976013, 0.4474000036716461, 0.43939998745918274, 0.0925000011920929, 0.40400001406669617, 0.14949999749660492, 0.03689999878406525, 0.22669999301433563, -0.08389999717473984, -0.052400000393390656, 0.27149999141693115, 0.10540000349283218, -0.006099999882280827, 0.2549000084400177, 0.2085999995470047, 0.18790000677108765, -0.03920000046491623, 0.21140000224113464, -0.029999999329447746, 0.019300000742077827, -0.05180000141263008, -0.011699999682605267, 0.06419999897480011, -0.022299999371170998, -0.17820000648498535, -0.007000000216066837, -0.18809999525547028, -0.18780000507831573, -0.019899999722838402, -0.03310000151395798, 0.0044999998062849045, -0.06639999896287918, -0.10010000318288803, -0.18960000574588776, 0.8385999798774719, 0.8339999914169312, 0.8331999778747559, 0.8310999870300293, 0.8309000134468079, 0.8306000232696533, 0.8302000164985657, 0.8296999931335449, 0.8296999931335449, 0.829200029373169, 0.828499972820282, 0.8284000158309937, 0.8281999826431274, 0.8274000287055969, 0.8269000053405762, 0.82669997215271, 0.826200008392334, 0.8259000182151794, 0.8256999850273132, 0.8256000280380249, 0.8252000212669373, 0.8251000046730042, 0.8248999714851379, 0.8248999714851379, 0.8248999714851379, 0.8242999911308289, 0.8241000175476074, 0.8238999843597412, 0.8237000107765198, 0.8234999775886536, 0.8226000070571899, 0.8183000087738037, 0.8223000168800354, 0.7907999753952026, 0.8156999945640564, 0.8148000240325928, 0.7960000038146973, 0.7910000085830688, 0.7857999801635742, 0.8105999827384949, 0.8069999814033508, 0.7627999782562256, 0.8131999969482422, 0.7900000214576721, 0.6237999796867371, 0.7706000208854675, 0.7609999775886536, 0.630299985408783, 0.6940000057220459, 0.6761999726295471, 0.7218999862670898, 0.14790000021457672, 0.22450000047683716, 0.2328999936580658, 0.19429999589920044, 0.1023000031709671, 0.6550999879837036, 0.24150000512599945, 0.5443999767303467, 0.5110999941825867, 0.023000000044703484, 0.11919999867677689, 0.26409998536109924, 0.1120000034570694, 0.05660000070929527, 0.16660000383853912, 0.15610000491142273, 0.2727999985218048, 0.05050000175833702, 0.23080000281333923, -0.05829999968409538, 0.08290000259876251, 0.07940000295639038, -0.18619999289512634, 0.2547999918460846, 0.10010000318288803, 0.11180000007152557, 0.1688999980688095, 0.07119999825954437, 0.046300001442432404, 0.1776999980211258, -0.25929999351501465, 0.01769999973475933, 0.15760000050067902, -0.0738999992609024, 0.0640999972820282, -0.18019999563694, 0.02449999935925007, -0.03539999946951866, 0.08060000091791153, -0.6173999905586243, 3.356300115585327, 3.354099988937378, 3.3498001098632812, 3.3410000801086426, 3.335200071334839, 3.334199905395508, 3.333400011062622, 3.3101999759674072, 3.308000087738037, 3.3071000576019287, 3.3071000576019287, 3.30679988861084, 3.303999900817871, 3.2994000911712646, 3.2987000942230225, 3.296600103378296, 3.295300006866455, 3.2948999404907227, 3.291100025177002, 3.288800001144409, 3.288300037384033, 3.2876999378204346, 3.2874999046325684, 3.287400007247925, 3.2873001098632812, 3.2871999740600586, 3.2869999408721924, 3.2867000102996826, 3.286400079727173, 3.28629994392395, 3.206700086593628, 3.2585999965667725, 3.1744000911712646, 3.2414000034332275, 2.731300115585327, 3.0945000648498535, 3.002000093460083, 2.537400007247925, 2.7525999546051025, 2.2669999599456787, 2.8290998935699463, 2.253999948501587, -0.10100000351667404, 0.39340001344680786, 0.24570000171661377, 2.502500057220459, 0.5187000036239624, -0.3018999993801117, 0.6721000075340271, 1.3638999462127686, 1.222599983215332, 0.6201000213623047, -0.6151000261306763, 0.18629999458789825, 0.48559999465942383, 2.0113000869750977, -0.38920000195503235, -0.13490000367164612, 0.8119000196456909, -0.43779999017715454, -0.8532999753952026, 0.17159999907016754, -0.6891999840736389, -0.45730000734329224, -0.9229999780654907, 0.24940000474452972, 0.8019999861717224, -0.029200000688433647, -0.06809999793767929, -0.21529999375343323, 0.002300000051036477, 0.5942999720573425, -0.37369999289512634, -0.12460000067949295, -0.41269999742507935, -0.7307999730110168, -0.6184999942779541, -0.34380000829696655, -0.7354000210762024, 5.003600120544434, 4.998899936676025, 4.989699840545654, 4.981400012969971, 4.978600025177002, 4.970900058746338, 4.965700149536133, 4.963600158691406, 4.963500022888184, 4.962600231170654, 4.952099800109863, 4.932700157165527, 4.931399822235107, 4.927199840545654, 4.921999931335449, 4.921899795532227, 4.919600009918213, 4.914899826049805, 4.913599967956543, 4.911499977111816, 4.909200191497803, 4.901899814605713, 4.894100189208984, 4.889800071716309, 4.876800060272217, 4.8765997886657715, 4.872600078582764, 4.864299774169922, 4.857600212097168, 4.8383002281188965, 4.35860013961792, 4.5879998207092285, 4.161099910736084, 4.5553998947143555, 4.23960018157959, 3.9677999019622803, 0.6654000282287598, -2.670300006866455, -2.0473999977111816, 0.45019999146461487, -2.482300043106079, 1.7308000326156616, 0.3716000020503998, -3.9581000804901123, -3.503999948501587, -2.7014000415802, 5.2307000160217285, 5.167699813842773, 5.136600017547607, 5.120800018310547, 5.117300033569336, 5.115099906921387, 5.1143999099731445, 5.106500148773193, 5.086699962615967, 5.024899959564209, 5.024199962615967, 5.021299839019775, 5.019199848175049, 5.0177001953125, 5.0167999267578125, 5.016200065612793, 5.01039981842041, 4.903900146484375, 4.903800010681152, 4.894700050354004, 4.89109992980957, 4.889400005340576, 4.860400199890137, 4.859600067138672, 4.859600067138672, 4.859600067138672, 4.858500003814697, 4.857500076293945, 4.85699987411499, 4.856599807739258, 4.653299808502197, 4.173900127410889, 3.6377999782562256, 4.317999839782715, 4.786799907684326, 4.786200046539307, 4.781000137329102, 4.785200119018555, 3.6359000205993652, 3.3677000999450684, 3.9212000370025635, 3.35509991645813, 3.67930006980896, 3.390399932861328, 0.8672000169754028, -0.7423999905586243, 1.3614000082015991, -0.10559999942779541, 0.3625999987125397, -2.1319000720977783, -1.0809999704360962, -0.35179999470710754, -1.6606999635696411, 1.0190000534057617, -2.7750000953674316, -2.6405999660491943, -1.1444000005722046, 0.8379999995231628, 0.6662999987602234, -1.9817999601364136, 0.8982999920845032, -0.6021999716758728, 0.8640999794006348, -0.3125, -2.219599962234497, -0.9686999917030334, -2.053999900817871, 0.5929999947547913, -3.243000030517578, -1.95169997215271, -1.781999945640564, -0.8385000228881836, -3.3015999794006348], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.34000015258789, -9.359399795532227, -9.49779987335205, -9.485699653625488, -9.497900009155273, -9.244799613952637, -9.779199600219727, -9.446100234985352, -9.637700080871582, -8.39330005645752, -9.847599983215332, -9.962900161743164, -8.564900398254395, -9.954899787902832, -9.965999603271484, -9.536700248718262, -9.79419994354248, -10.07800006866455, -10.065199851989746, -10.152000427246094, -9.537500381469727, -10.130599975585938, -9.771100044250488, -9.995499610900879, -10.176199913024902, -10.212400436401367, -10.177300453186035, -10.224699974060059, -10.24839973449707, -10.201700210571289, -7.78879976272583, -8.123000144958496, -9.212800025939941, -9.95989990234375, -9.787599563598633, -8.272199630737305, -7.658699989318848, -9.907899856567383, -6.0177998542785645, -6.789000034332275, -8.873499870300293, -9.365599632263184, -9.404000282287598, -6.564700126647949, -9.360699653625488, -6.372600078582764, -4.526000022888184, -8.084400177001953, -8.183600425720215, -9.160200119018555, -5.382599830627441, -7.295499801635742, -3.4651999473571777, -7.138000011444092, -3.2632999420166016, -7.494500160217285, -5.028600215911865, -6.743199825286865, -7.416600227355957, -7.3414998054504395, -4.0040998458862305, -7.194499969482422, -4.6894001960754395, -3.6970999240875244, -5.454999923706055, -3.3024001121520996, -3.7783000469207764, -6.185100078582764, -4.984300136566162, -4.517000198364258, -6.132299900054932, -5.945799827575684, -5.933499813079834, -4.826099872589111, -6.142099857330322, -4.906400203704834, -5.1529998779296875, -4.863999843597412, -5.084099769592285, -5.4274001121521, -5.0843000411987305, -4.447700023651123, -5.201700210571289, -4.660299777984619, -4.757699966430664, -5.303400039672852, -5.316500186920166, -5.515600204467773, -5.441299915313721, -5.405200004577637, -5.286200046539307, -9.338600158691406, -9.706700325012207, -9.734399795532227, -9.430899620056152, -9.657099723815918, -9.394399642944336, -9.785200119018555, -9.469900131225586, -9.617199897766113, -9.987500190734863, -9.887299537658691, -9.965499877929688, -10.061599731445312, -9.62909984588623, -10.062700271606445, -10.062700271606445, -9.761300086975098, -10.003600120544434, -10.089900016784668, -10.184800148010254, -10.089500427246094, -10.090399742126465, -10.0516996383667, -10.198100090026855, -10.156700134277344, -10.243800163269043, -10.200400352478027, -10.158499717712402, -10.053799629211426, -9.97029972076416, -9.862199783325195, -9.527099609375, -9.970399856567383, -7.462500095367432, -9.619999885559082, -9.585200309753418, -8.826199531555176, -8.75979995727539, -8.637700080871582, -9.565500259399414, -9.472599983215332, -8.375800132751465, -9.683099746704102, -9.244500160217285, -6.8059000968933105, -9.12279987335205, -9.014200210571289, -7.6016998291015625, -8.352399826049805, -8.227800369262695, -8.770600318908691, -3.0706000328063965, -4.045000076293945, -4.336999893188477, -4.277900218963623, -3.6236000061035156, -8.182600021362305, -4.855100154876709, -7.4079999923706055, -7.169899940490723, -3.7109999656677246, -4.667699813842773, -5.723199844360352, -4.764400005340576, -4.4542999267578125, -5.191100120544434, -5.14900016784668, -6.014699935913086, -4.76170015335083, -5.791600227355957, -4.154900074005127, -4.979000091552734, -4.993000030517578, -3.601099967956543, -5.957900047302246, -5.183300018310547, -5.263199806213379, -5.611100196838379, -5.212200164794922, -5.125999927520752, -5.731800079345703, -3.9395999908447266, -5.177000045776367, -5.716700077056885, -5.163599967956543, -5.525300025939941, -5.019100189208984, -5.49560022354126, -5.526899814605713, -5.670000076293945, -5.496500015258789, -8.662500381469727, -8.544699668884277, -8.732799530029297, -8.833700180053711, -8.94159984588623, -8.94260025024414, -8.893199920654297, -9.048800468444824, -9.111000061035156, -9.175100326538086, -8.935400009155273, -9.176199913024902, -9.121500015258789, -9.251799583435059, -9.183199882507324, -9.253999710083008, -9.253999710083008, -9.259900093078613, -9.261199951171875, -9.26259994506836, -9.33590030670166, -9.336299896240234, -9.336299896240234, -9.336400032043457, -9.336799621582031, -9.33650016784668, -9.337400436401367, -9.336899757385254, -9.3371000289917, -9.337699890136719, -7.680699825286865, -8.855500221252441, -8.235300064086914, -8.996199607849121, -7.453100204467773, -8.711000442504883, -8.431900024414062, -7.150199890136719, -7.962600231170654, -6.782700061798096, -8.335000038146973, -7.234499931335449, -3.515899896621704, -4.418799877166748, -4.226500034332275, -7.925099849700928, -4.839000225067139, -4.0278000831604, -5.433599948883057, -6.402100086212158, -6.237800121307373, -5.465700149536133, -3.8336000442504883, -5.008399963378906, -5.391900062561035, -7.3618998527526855, -4.658699989318848, -4.973800182342529, -6.158100128173828, -4.948800086975098, -4.533599853515625, -5.578999996185303, -4.785799980163574, -5.027200222015381, -4.6570000648498535, -5.7845001220703125, -6.30649995803833, -5.618599891662598, -5.588099956512451, -5.590199947357178, -5.7778000831604, -6.177000045776367, -5.657199859619141, -5.806300163269043, -5.717700004577637, -5.609899997711182, -5.6803998947143555, -5.835299968719482, -5.831999778747559, -5.685200214385986, -5.967199802398682, -6.244900226593018, -6.440199851989746, -6.309599876403809, -6.59630012512207, -6.733699798583984, -6.716800212860107, -6.707200050354004, -6.789100170135498, -6.934899806976318, -6.54610013961792, -7.183599948883057, -7.2357001304626465, -7.289100170135498, -7.289299964904785, -7.3094000816345215, -6.938300132751465, -7.368599891662598, -7.387899875640869, -7.4095001220703125, -7.47160005569458, -7.543700218200684, -7.567699909210205, -7.6707000732421875, -7.668399810791016, -7.697199821472168, -7.754799842834473, -7.709700107574463, -7.916800022125244, -5.317399978637695, -6.826099872589111, -5.893799781799316, -7.128200054168701, -6.569399833679199, -6.935299873352051, -6.4232001304626465, -6.396200180053711, -6.617300033569336, -7.010200023651123, -6.954500198364258, -7.184999942779541, -7.1946001052856445, -7.176700115203857, -7.184299945831299, -7.212399959564209, -7.007800102233887, -7.471099853515625, -7.594699859619141, -7.699100017547607, -7.753300189971924, -7.754899978637695, -7.75439977645874, -7.756700038909912, -7.38070011138916, -8.147700309753418, -8.147500038146973, -8.149700164794922, -8.150199890136719, -8.151399612426758, -8.079099655151367, -8.151100158691406, -8.007399559020996, -8.521599769592285, -8.521599769592285, -8.527999877929688, -8.528900146484375, -8.575900077819824, -8.651700019836426, -8.651800155639648, -8.651900291442871, -8.651900291442871, -8.653800010681152, -8.655400276184082, -8.65250015258789, -8.654500007629395, -7.770299911499023, -6.972499847412109, -6.984799861907959, -7.952700138092041, -8.572799682617188, -8.573100090026855, -8.569100379943848, -8.573399543762207, -7.490900039672852, -7.295599937438965, -7.845699787139893, -7.442500114440918, -7.753600120544434, -7.579899787902832, -6.593299865722656, -5.839000225067139, -6.8734002113342285, -6.318399906158447, -6.653299808502197, -5.865900039672852, -6.253300189971924, -6.50629997253418, -6.132800102233887, -6.963699817657471, -5.993500232696533, -6.055500030517578, -6.502200126647949, -7.025300025939941, -7.005000114440918, -6.551799774169922, -7.074999809265137, -6.873899936676025, -7.095099925994873, -6.982100009918213, -6.730500221252441, -6.991199970245361, -6.93310022354126, -7.187900066375732, -6.923299789428711, -7.041399955749512, -7.065400123596191, -7.118500232696533, -7.027500152587891]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 3, 5, 5, 3, 5, 3, 2, 1, 5, 1, 5, 4, 3, 5, 3, 1, 2, 3, 2, 1, 2, 3, 2, 1, 2, 3, 5, 2, 5, 1, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 1, 2, 3, 5, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 3, 3, 1, 3, 5, 5, 5, 5, 2, 3, 1, 2, 4, 3, 1, 2, 3, 2, 1, 2, 3, 5, 2, 1, 3, 3, 2, 1, 2, 3, 4, 5, 3, 4, 2, 3, 1, 2, 5, 1, 2, 5, 1, 3, 3, 5, 5, 1, 2, 3, 5, 5, 3, 1, 2, 4, 5, 5, 5, 1, 2, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 1, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 2, 3, 5, 5, 1, 2, 3, 4, 5, 5, 3, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 1, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 4, 1, 4, 1, 3, 1, 2, 3, 5, 2, 1, 5, 4, 1, 2, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 4, 2, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 3, 2, 3, 2, 1, 2, 3, 5, 5, 4, 1, 2, 3, 4, 1, 2, 3, 1, 4, 2, 1, 2, 3, 2, 1, 2, 4, 4, 4, 1, 2, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 1, 2, 3, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 2, 2, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 4, 1, 2, 3, 4, 5, 4, 1, 2, 3, 1, 1, 2, 3, 4, 5, 1, 2, 3, 2, 1, 2, 3, 2, 1, 2, 3, 4, 5, 5, 1, 2, 1, 3, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 2, 4, 3, 1, 2, 3, 1, 2, 5, 2, 4, 1, 1, 2, 3, 4, 5, 2, 1, 2, 5, 1, 1, 2, 4, 5, 4, 1, 2, 3, 1, 2, 3, 2, 2, 4, 1, 2, 4, 1, 2, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 5, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 1, 2, 3, 2, 1, 3, 1, 2, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 5, 2, 1, 2, 2, 2, 2, 2, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 4, 1, 2, 3, 3, 1, 3, 5, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 3, 1, 2, 3, 4, 1, 2, 1, 1, 2, 3, 4, 5, 3, 4, 4, 1, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 4, 4], \"Freq\": [0.758032500743866, 0.1928328275680542, 0.006649408023804426, 0.03989644721150398, 0.006649408023804426, 0.5359104871749878, 0.41075772047042847, 0.03636917099356651, 0.01283617876470089, 0.004278726410120726, 0.9019493460655212, 0.0739302784204483, 0.00985736958682537, 0.004928684793412685, 0.004928684793412685, 0.5657097101211548, 0.8133578896522522, 0.9582195281982422, 0.5659044981002808, 0.5652976632118225, 0.7591478228569031, 0.6584779620170593, 0.888350248336792, 0.9921531081199646, 0.9795495867729187, 0.9353840351104736, 0.9695069193840027, 0.6595888137817383, 0.7686769366264343, 0.8135651350021362, 0.9387044310569763, 0.813125491142273, 0.33170458674430847, 0.27139467000961304, 0.3920145332813263, 0.990754246711731, 0.9584479928016663, 0.0063473377376794815, 0.03173668682575226, 0.979042112827301, 0.6484861969947815, 0.011790658347308636, 0.3065571188926697, 0.02358131669461727, 0.9845089912414551, 0.8255959749221802, 0.4438161551952362, 0.4438161551952362, 0.5538750290870667, 0.31494852900505066, 0.10860294103622437, 0.010860294103622437, 0.010860294103622437, 0.657380998134613, 0.786051332950592, 0.1911712884902954, 0.022490739822387695, 0.6619424819946289, 0.06304214149713516, 0.24166154861450195, 0.03152107074856758, 0.9337376952171326, 0.19101928174495697, 0.04775482043623924, 0.8118319511413574, 0.6560882925987244, 0.3299205005168915, 0.013630152679979801, 0.00021241795911919326, 0.00017701496835798025, 0.6648361682891846, 0.2821156680583954, 0.049247123301029205, 0.0035176516976207495, 0.38848230242729187, 0.20143526792526245, 0.4028705358505249, 0.41336217522621155, 0.5617116689682007, 0.024484867230057716, 0.00048009544843807817, 0.8135366439819336, 0.9192188382148743, 0.9800961017608643, 0.813685417175293, 0.6936208009719849, 0.6955910921096802, 0.9055943489074707, 0.658703625202179, 0.9929673075675964, 0.8130960464477539, 0.24257849156856537, 0.43664127588272095, 0.33960989117622375, 0.911199152469635, 0.08052016794681549, 0.16104033589363098, 0.7246814966201782, 0.9710326790809631, 0.06298310309648514, 0.377898633480072, 0.5668479800224304, 0.8693854212760925, 0.9791858792304993, 0.9856225252151489, 0.9258741736412048, 0.81324702501297, 0.9721971750259399, 0.6826826930046082, 0.2837880551815033, 0.03235714137554169, 0.0010608899174258113, 0.0005304449587129056, 0.9420258402824402, 0.7536466121673584, 0.9749929904937744, 0.8894864320755005, 0.20754843950271606, 0.6226453185081482, 0.15566132962703705, 0.7416359782218933, 0.0824039950966835, 0.164807990193367, 0.18427324295043945, 0.7370929718017578, 0.8650882244110107, 0.692761242389679, 0.6597152352333069, 0.897049069404602, 0.09414307773113251, 0.0053796046413481236, 0.0013449011603370309, 0.6940145492553711, 0.9410061836242676, 0.4247375428676605, 0.3033839464187622, 0.12135358154773712, 0.18203036487102509, 0.9356352090835571, 0.9372386336326599, 0.4802128076553345, 0.39290139079093933, 0.1309671252965927, 0.5626114010810852, 0.1064399927854538, 0.31171712279319763, 0.02280857041478157, 0.5023815035820007, 0.4496726393699646, 0.047437991946935654, 0.00021962032769806683, 0.0003294305060990155, 0.9654790163040161, 0.16286732256412506, 0.8143366575241089, 0.9633544087409973, 0.6339253187179565, 0.2379852533340454, 0.12425778806209564, 0.0021060642320662737, 0.4613068401813507, 0.5061079263687134, 0.03208336979150772, 0.0002890393661800772, 0.9727846384048462, 0.030399519950151443, 0.6590921878814697, 0.628956139087677, 0.5021302700042725, 0.47359806299209595, 0.02364099584519863, 0.0004446582170203328, 0.00018527425709180534, 0.6010976433753967, 0.7564262747764587, 0.5778583288192749, 0.3621349334716797, 0.05763007700443268, 0.000778784800786525, 0.00155756960157305, 0.11960408836603165, 0.7176245450973511, 0.11960408836603165, 0.6760463118553162, 0.2759372889995575, 0.039665982127189636, 0.010347647592425346, 0.6157320737838745, 0.35491886734962463, 0.028915895149111748, 8.145322499331087e-05, 0.0003529639798216522, 0.9769918918609619, 0.02382907085120678, 0.9788198471069336, 0.4395829141139984, 0.5051414370536804, 0.05381101369857788, 0.00018947539501823485, 0.0015158031601458788, 0.5128235816955566, 0.45573702454566956, 0.031051265075802803, 0.4952085316181183, 0.47805261611938477, 0.025830263271927834, 0.0005782894440926611, 0.0003855263057630509, 0.2425973117351532, 0.0808657705783844, 0.6469261646270752, 0.9797878861427307, 0.9133927822113037, 0.9910896420478821, 0.8321359157562256, 0.531530499458313, 0.4381505250930786, 0.029863769188523293, 0.0004457278992049396, 0.9837725758552551, 0.9931293725967407, 0.602706253528595, 0.9004269242286682, 0.5497535467147827, 0.2565516531467438, 0.18325117230415344, 0.07070153206586838, 0.9191199541091919, 0.5230373740196228, 0.4629279673099518, 0.013816619291901588, 0.00014243937039282173, 0.00014243937039282173, 0.8297722935676575, 0.16560211777687073, 0.0017617245903238654, 0.0017617245903238654, 0.4746163487434387, 0.49844247102737427, 0.023349599912762642, 0.0019060897175222635, 0.0019060897175222635, 0.8208701014518738, 0.16673924028873444, 0.004275365266948938, 0.008550730533897877, 0.05524377524852753, 0.9391441941261292, 0.8549339175224304, 0.9574561715126038, 0.65871661901474, 0.623089075088501, 0.30117788910865784, 0.07092957943677902, 0.0032736726570874453, 0.16497698426246643, 0.24746547639369965, 0.6599079370498657, 0.040706634521484375, 0.9362525343894958, 0.020353317260742188, 0.12060564756393433, 0.361816942691803, 0.4824225902557373, 0.9726972579956055, 0.9553310871124268, 0.03453003987669945, 0.011510012671351433, 0.958145022392273, 0.9721329212188721, 0.027775226160883904, 0.9567813277244568, 0.27984264492988586, 0.6970154643058777, 0.010364541783928871, 0.012955677695572376, 0.5604645609855652, 0.7993698716163635, 0.12800075113773346, 0.34133532643318176, 0.02844461053609848, 0.5120030045509338, 0.9687947034835815, 0.037991948425769806, 0.813382089138031, 0.9889389276504517, 0.9425233006477356, 0.985996425151825, 0.8528006672859192, 0.13152647018432617, 0.014849762432277203, 1.0004361867904663, 0.9967347979545593, 0.08627686649560928, 0.9490455389022827, 0.9408116936683655, 0.9789697527885437, 0.9618386030197144, 0.018859580159187317, 0.9936714172363281, 0.5015182495117188, 0.4460771977901459, 0.051936130970716476, 0.0003186265821568668, 0.0003186265821568668, 0.5258941650390625, 0.45244932174682617, 0.020636044442653656, 0.0004062213411089033, 0.00048746561515145004, 0.4704606533050537, 0.5105978846549988, 0.01743665337562561, 0.0009869803907349706, 0.9798692464828491, 0.9839463233947754, 0.00870748981833458, 0.5246122479438782, 0.4325815439224243, 0.04098533093929291, 0.0011177818523719907, 0.0007451878627762198, 0.6538973450660706, 0.3292565643787384, 0.015385820530354977, 0.0010257213143631816, 0.0005128606571815908, 0.534450113773346, 0.40378057956695557, 0.059644944965839386, 0.0011772027937695384, 0.0011772027937695384, 0.8135345578193665, 0.6815375685691833, 0.3016958236694336, 0.01650722324848175, 0.00017560874402988702, 0.9423728585243225, 0.03365617245435715, 0.0033656172454357147, 0.02019370347261429, 0.9883829355239868, 0.5879450440406799, 0.39708390831947327, 0.014202271588146687, 0.00014492114132735878, 0.0007246056920848787, 0.6942006349563599, 0.29394081234931946, 0.011371017433702946, 0.0005685508949682117, 0.9574073553085327, 0.8325687050819397, 0.16124849021434784, 0.005758874583989382, 0.0008226963691413403, 0.5159854292869568, 0.419913649559021, 0.06244664639234543, 0.00040029900264926255, 0.0008005980052985251, 0.8431004285812378, 0.1073036938905716, 0.035767897963523865, 0.002554849721491337, 0.010219398885965347, 0.7925816178321838, 0.20126231014728546, 0.005343247205018997, 0.8040955662727356, 0.054851990193128586, 0.9427685737609863, 0.0034282493870705366, 0.992958128452301, 0.9859238862991333, 0.8679124712944031, 0.1288875937461853, 0.0010394160635769367, 0.0020788321271538734, 0.35308486223220825, 0.609398365020752, 0.023538991808891296, 0.013077217154204845, 0.442745178937912, 0.538513720035553, 0.016575319692492485, 0.0018417021492496133, 0.4385753870010376, 0.5397519469261169, 0.020252548158168793, 0.0008618105202913284, 0.0006894484395161271, 0.9759839177131653, 0.43845170736312866, 0.5192644000053406, 0.04087526723742485, 0.0005470876931212842, 0.0009378646500408649, 0.5087504982948303, 0.48166424036026, 0.009314245544373989, 0.00010706028842832893, 0.00010706028842832893, 0.7705695033073425, 0.8972088694572449, 0.6888995170593262, 0.24926213920116425, 0.3115776777267456, 0.020771844312548637, 0.41543689370155334, 0.020771844312548637, 1.0003050565719604, 0.9978877902030945, 0.9462285041809082, 0.9777677655220032, 0.4811782240867615, 0.5005524158477783, 0.017468515783548355, 0.00031760940328240395, 0.0006352188065648079, 0.9780207872390747, 0.1065286323428154, 0.8759020566940308, 0.011836514808237553, 0.9869181513786316, 0.7681559324264526, 0.2222125083208084, 0.009023858234286308, 0.00028199556982144713, 0.00028199556982144713, 0.2334412783384323, 0.735847532749176, 0.027911456301808357, 0.9931970834732056, 0.025095811113715172, 0.9410929679870605, 0.025095811113715172, 0.9712976813316345, 0.7532564997673035, 0.23057915270328522, 0.0153797697275877, 0.0001174028220702894, 0.0005870141321793199, 0.6586753726005554, 0.9784096479415894, 0.02223658189177513, 0.9834266304969788, 0.014678009785711765, 0.9738549590110779, 0.7517353296279907, 0.5118669867515564, 0.4726414382457733, 0.014599642716348171, 0.00017589930212125182, 0.0008794965106062591, 0.44277483224868774, 0.5351844429969788, 0.021698391065001488, 0.00019145639089401811, 0.00019145639089401811, 0.756568193435669, 0.5174387693405151, 0.46458134055137634, 0.017196275293827057, 0.00042285924428142607, 0.00042285924428142607, 0.9570907354354858, 0.9183477759361267, 0.8138031959533691, 0.3546772599220276, 0.1418709009885788, 0.4965481758117676, 0.04042932391166687, 0.9433508515357971, 0.01347644068300724, 0.9572084546089172, 0.9499208927154541, 0.988159716129303, 0.49645283818244934, 0.4633372724056244, 0.03788645192980766, 0.0011225615162402391, 0.0011225615162402391, 0.9823864102363586, 0.9867818355560303, 0.6905038356781006, 0.2301679402589798, 0.9836397767066956, 0.26494547724723816, 0.26494547724723816, 0.441575825214386, 0.6592804789543152, 0.9274325370788574, 0.8999451398849487, 0.0599963404238224, 0.03272527828812599, 0.9448767900466919, 0.015239948406815529, 0.045719847083091736, 0.9557777047157288, 0.317647248506546, 0.635294497013092, 0.9872189164161682, 0.022958580404520035, 0.9800421595573425, 0.5713794231414795, 0.19045980274677277, 0.38091960549354553, 0.2611372768878937, 0.7118408679962158, 0.02321220189332962, 0.001934350118972361, 0.6982665061950684, 0.25364381074905396, 0.03779790177941322, 0.0029840448405593634, 0.006962771527469158, 0.937878429889679, 0.9995459318161011, 0.962300717830658, 0.026008127257227898, 0.028640449047088623, 0.9737752676010132, 0.18957003951072693, 0.797397792339325, 0.012036193162202835, 0.14396753907203674, 0.8562279939651489, 0.151146799325943, 0.8411648273468018, 0.006571600213646889, 0.9969921708106995, 0.9951779246330261, 0.007008295506238937, 0.02933291718363762, 0.9679862856864929, 0.9677167534828186, 0.019749321043491364, 0.019749321043491364, 0.5982595682144165, 0.36623314023017883, 0.03071632795035839, 0.0018902354640886188, 0.002835353370755911, 0.6436851024627686, 0.29693806171417236, 0.04789323732256889, 0.001915729371830821, 0.009578647091984749, 0.9856072664260864, 0.8817774653434753, 0.11365946382284164, 0.0036664344370365143, 0.0006110724061727524, 0.9825093150138855, 0.07851693034172058, 0.9107964038848877, 0.9916557669639587, 0.9816252589225769, 0.9850054979324341, 0.9823690056800842, 0.5642399787902832, 0.41262078285217285, 0.022742876783013344, 0.00021659882622770965, 0.00021659882622770965, 0.8836506605148315, 0.9084409475326538, 0.6107275485992432, 0.1908523589372635, 0.0381704717874527, 0.1526818871498108, 0.4874187409877777, 0.4389618933200836, 0.07221018522977829, 0.0009501339518465102, 0.03230166435241699, 0.969049870967865, 0.979128360748291, 0.1912917196750641, 0.8020828366279602, 0.0033559950534254313, 0.08309146761894226, 0.9140061736106873, 0.7572187185287476, 0.15989916026592255, 0.8240956664085388, 0.018449902534484863, 0.9890817403793335, 0.9816918969154358, 0.8095166087150574, 0.8269602060317993, 0.13705238699913025, 0.03484382852911949, 0.9468715786933899, 0.6187594532966614, 0.06187594681978226, 0.3093797266483307, 0.6043226718902588, 0.6043651103973389, 0.51353520154953, 0.4781755208969116, 0.007844701409339905, 0.00011708509555319324, 0.00023417019110638648, 0.48658043146133423, 0.4957275092601776, 0.017290225252509117, 0.00013385980855673552, 0.0002900295949075371, 0.42567357420921326, 0.5568962693214417, 0.016358382999897003, 0.0007112340535968542, 0.0003556170267984271, 0.5394106507301331, 0.44780370593070984, 0.01070321723818779, 0.0003148005052935332, 0.0015740025555714965, 0.5254006385803223, 0.4352583885192871, 0.03847143426537514, 0.00032193667721003294, 0.0004829050158150494, 0.9999917149543762, 0.7550153732299805, 0.7559812664985657, 0.6383860111236572, 0.3464362323284149, 0.014638150110840797, 0.00040661529055796564, 0.9737688899040222, 0.0165045578032732, 0.978734016418457, 0.5489943623542786, 0.43752190470695496, 0.012701285071671009, 0.00018678359629120678, 0.0005603507743217051, 0.9413253664970398, 0.9067478179931641, 0.9270378947257996, 0.9727710485458374, 0.9681717157363892, 0.5292266607284546, 0.44566455483436584, 0.013927017338573933, 0.011605847626924515, 0.6638727188110352, 0.30704766511917114, 0.02829449623823166, 0.0002619860752020031, 0.0007859581965021789, 0.8972471356391907, 0.5804307460784912, 0.40332743525505066, 0.01605149731040001, 0.00010736787953646854, 5.368393976823427e-05, 0.4786915183067322, 0.49990278482437134, 0.02121126465499401, 0.00017975649097934365, 0.9778398871421814, 0.518757164478302, 0.4591238498687744, 0.02198868989944458, 0.00017590951756574214, 0.00017590951756574214, 0.6518846750259399, 0.31606531143188477, 0.028580373153090477, 0.003362396964803338, 0.6144152283668518, 0.35705554485321045, 0.02796897478401661, 0.0003383343864697963, 0.00022555624309461564, 0.878118634223938, 0.4377880096435547, 0.5443164110183716, 0.015322580002248287, 0.000291858654236421, 0.002334869233891368, 0.42145994305610657, 0.5515511631965637, 0.021830378100275993, 0.0008910358301363885, 0.004455179441720247, 0.9221799969673157, 0.9817368984222412, 0.8443551063537598], \"Term\": [\"!\", \"!\", \"!\", \"!\", \"!\", \"&\", \"&\", \"&\", \"&\", \"&\", \",\", \",\", \",\", \",\", \",\", \"3:\", \"400sqft\", \"44\", \"4:\", \"5:\", \"Anton\", \"BEST!\", \"Bady\", \"Bay\", \"Benedict\", \"Bim\", \"Buffalo\", \"COMPANY\", \"Capitol\", \"Caramelo\", \"Chief!\", \"Conservatory\", \"Delicious\", \"Delicious\", \"Delicious\", \"Downtown\", \"Dr.\", \"Dr.\", \"Dr.\", \"Dunkin\", \"Excellent\", \"Excellent\", \"Excellent\", \"Excellent\", \"Fremont\", \"Glo\", \"Grace\", \"Grace\", \"Great\", \"Great\", \"Great\", \"Great\", \"Great\", \"Guaranteed!\", \"He\", \"He\", \"He\", \"Highly\", \"Highly\", \"Highly\", \"Highly\", \"Hobby\", \"Huge\", \"Huge\", \"Huge\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I've\", \"I've\", \"I've\", \"I've\", \"Indian\", \"Indian\", \"Indian\", \"It\", \"It\", \"It\", \"It\", \"Iwashi\", \"Jeremy\", \"Josh\", \"Kabab\", \"Keri\", \"Kia\", \"Killer\", \"L'ambiance\", \"LV\", \"Lahore\", \"Le\", \"Le\", \"Le\", \"Lopez\", \"Lovely\", \"Lovely\", \"Lovely\", \"MGM\", \"MUST\", \"MUST\", \"MUST\", \"Main.\", \"Mandalay\", \"Mary\", \"Middle\", \"Miku\", \"Momofuku\", \"My\", \"My\", \"My\", \"My\", \"My\", \"Northern\", \"Nous\", \"OK,\", \"Pastries\", \"Ramen\", \"Ramen\", \"Ramen\", \"Ray\", \"Ray\", \"Ray\", \"Sammie\", \"Sammie\", \"Sardine\", \"Schwarts'\", \"Schwartz's\", \"She\", \"She\", \"She\", \"She\", \"Singapore\", \"Solon\", \"Studio\", \"Studio\", \"Studio\", \"Studio\", \"Sundays,\", \"Suzanne\", \"Taiwanese\", \"Taiwanese\", \"Taiwanese\", \"Thai\", \"Thai\", \"Thai\", \"Thai\", \"The\", \"The\", \"The\", \"The\", \"The\", \"Tower\", \"Turkish\", \"Turkish\", \"Un\", \"Very\", \"Very\", \"Very\", \"Very\", \"We\", \"We\", \"We\", \"We\", \"What's\", \"What's\", \"Wonderful,\", \"Yuk!\", \"a\", \"a\", \"a\", \"a\", \"a\", \"agedashi\", \"airbrush\", \"always\", \"always\", \"always\", \"always\", \"always\", \"always.\", \"always.\", \"always.\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"and\", \"and\", \"and\", \"and\", \"and\", \"appointment\", \"appointment\", \"appointment.\", \"are\", \"are\", \"are\", \"are\", \"are\", \"as\", \"as\", \"as\", \"at\", \"at\", \"at\", \"at\", \"at\", \"au\", \"au\", \"au\", \"auto\", \"avec\", \"balloons\", \"basil.\", \"be\", \"be\", \"be\", \"be\", \"beds\", \"bf\", \"bind\", \"bi\\u00e8res\", \"blow\", \"blow\", \"blow\", \"bus\", \"bus\", \"but\", \"but\", \"but\", \"but\", \"but\", \"called\", \"called\", \"called\", \"called\", \"can\", \"can\", \"can\", \"can\", \"can\", \"car\", \"car\", \"car\", \"car\", \"casino\", \"casino\", \"ce\", \"cha\", \"chaleureux\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chowder\", \"chowder\", \"chowder\", \"city.\", \"city.\", \"city.\", \"clam\", \"clam\", \"clam\", \"climbing\", \"color\", \"color\", \"color\", \"commands\", \"compare\", \"compare\", \"couch\", \"cream\", \"cream\", \"cream\", \"cream\", \"cutter\", \"dans\", \"de\", \"de\", \"de\", \"de\", \"dealership\", \"dealership\", \"deftly\", \"dental\", \"des\", \"district\", \"done\", \"done\", \"done\", \"elevator\", \"emailed\", \"en\", \"en\", \"est\", \"et\", \"experience!\", \"experience!\", \"fingers\", \"food\", \"food\", \"food\", \"food\", \"food\", \"for\", \"for\", \"for\", \"for\", \"for\", \"from\", \"from\", \"from\", \"from\", \"funny,\", \"gel\", \"gel\", \"good\", \"good\", \"good\", \"good\", \"good\", \"got\", \"got\", \"got\", \"got\", \"got\", \"great\", \"great\", \"great\", \"great\", \"great\", \"grooming,\", \"had\", \"had\", \"had\", \"had\", \"hair\", \"hair\", \"hair\", \"hair\", \"haircut\", \"have\", \"have\", \"have\", \"have\", \"have\", \"he\", \"he\", \"he\", \"he\", \"helpful!\", \"her\", \"her\", \"her\", \"her\", \"here\", \"here\", \"here\", \"here\", \"here\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"him\", \"him\", \"him\", \"holiday.\", \"hotel\", \"hotel\", \"hotel\", \"hotel,\", \"hotels\", \"i\", \"i\", \"i\", \"i\", \"ice\", \"ice\", \"ice\", \"ice\", \"if\", \"if\", \"if\", \"if\", \"in\", \"in\", \"in\", \"in\", \"in\", \"install\", \"is\", \"is\", \"is\", \"is\", \"is\", \"it\", \"it\", \"it\", \"it\", \"it\", \"j'ai\", \"je\", \"keratin\", \"la\", \"la\", \"la\", \"la\", \"la\", \"lash\", \"laundry\", \"le\", \"les\", \"like\", \"like\", \"like\", \"like\", \"like\", \"mais\", \"mall\", \"mall\", \"mall\", \"manicure\", \"me\", \"me\", \"me\", \"me\", \"me\", \"meat\", \"meat\", \"meat\", \"meatballs\", \"movie\", \"movie\", \"movie\", \"museum\", \"my\", \"my\", \"my\", \"my\", \"my\", \"n'ai\", \"nail\", \"nail\", \"nails\", \"nails\", \"nails.\", \"ne\", \"not\", \"not\", \"not\", \"not\", \"not\", \"of\", \"of\", \"of\", \"of\", \"of\", \"omelet,\", \"on\", \"on\", \"on\", \"on\", \"on\", \"opposite\", \"ou\", \"owing\", \"pad\", \"pad\", \"pad\", \"park\", \"park\", \"park\", \"park.\", \"pas\", \"pepperoni\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plays\", \"plumbing\", \"poker\", \"poker\", \"polish\", \"pour\", \"pour\", \"pour\", \"price!!!\", \"pris\", \"professional\", \"professional\", \"professional\", \"professional.\", \"professional.\", \"professional.\", \"public\", \"que\", \"que\", \"questions.\", \"questions.\", \"qui\", \"quick!\", \"quick!\", \"quick!\", \"quite\", \"quite\", \"quite\", \"quite\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"reef\", \"repair.\", \"resort\", \"resort\", \"restaurants,\", \"restaurants,\", \"room\", \"room\", \"room\", \"room.\", \"room.\", \"rooms\", \"rooms\", \"rooms\", \"rooms.\", \"salon\", \"salon\", \"sandwiches.\", \"sandwiches.\", \"scheduled\", \"scheduled\", \"scheduled\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service.\", \"service.\", \"service.\", \"service.\", \"service.\", \"services.\", \"she\", \"she\", \"she\", \"she\", \"shelf\", \"show.\", \"show.\", \"shuttle\", \"signage\", \"sleep\", \"smoking\", \"so\", \"so\", \"so\", \"so\", \"so\", \"socializing\", \"sont\", \"spray\", \"spray\", \"spray\", \"spray\", \"staff\", \"staff\", \"staff\", \"staff\", \"stage\", \"stage\", \"stars)\", \"stay\", \"stay\", \"stay\", \"staying\", \"staying\", \"steal.\", \"strip\", \"strip\", \"strip\", \"stylist\", \"suite\", \"sur\", \"sweet\", \"sweet\", \"sweet\", \"talent\", \"tan\", \"tan\", \"tan\", \"tar\", \"tar,\", \"that\", \"that\", \"that\", \"that\", \"that\", \"the\", \"the\", \"the\", \"the\", \"the\", \"there\", \"there\", \"there\", \"there\", \"there\", \"they\", \"they\", \"they\", \"they\", \"they\", \"this\", \"this\", \"this\", \"this\", \"this\", \"thorough\", \"tidy.\", \"tiki\", \"time\", \"time\", \"time\", \"time\", \"tire\", \"tire\", \"tires\", \"to\", \"to\", \"to\", \"to\", \"to\", \"tom\", \"tr\\u00e8s\", \"un\", \"understanding\", \"une\", \"use\", \"use\", \"use\", \"use\", \"very\", \"very\", \"very\", \"very\", \"very\", \"vous\", \"was\", \"was\", \"was\", \"was\", \"was\", \"we\", \"we\", \"we\", \"we\", \"welcoming.\", \"were\", \"were\", \"were\", \"were\", \"were\", \"will\", \"will\", \"will\", \"will\", \"with\", \"with\", \"with\", \"with\", \"with\", \"y\", \"you\", \"you\", \"you\", \"you\", \"you\", \"your\", \"your\", \"your\", \"your\", \"your\", \"yuk\", \"\\u00e0\", \"\\u00e9tait\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 3, 5, 1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1545229129983620569687705908\", ldavis_el1545229129983620569687705908_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1545229129983620569687705908\", ldavis_el1545229129983620569687705908_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1545229129983620569687705908\", ldavis_el1545229129983620569687705908_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3      0.180386  0.007663       1        1  52.913330\n",
       "2      0.175157 -0.001054       2        1  42.756783\n",
       "4      0.058705 -0.022295       3        1   3.198058\n",
       "0     -0.234472 -0.053594       4        1   0.654198\n",
       "1     -0.179776  0.069281       5        1   0.477630, topic_info=    Category          Freq  Term         Total  loglift  logprob\n",
       "20   Default  36830.000000   and  36830.000000  30.0000  30.0000\n",
       "62   Default  44823.000000   the  44823.000000  29.0000  29.0000\n",
       "15   Default  26987.000000     a  26987.000000  28.0000  28.0000\n",
       "85   Default  12795.000000    is  12795.000000  27.0000  27.0000\n",
       "13   Default   9106.000000   The   9106.000000  26.0000  26.0000\n",
       "..       ...           ...   ...           ...      ...      ...\n",
       "11    Topic5      5.267946     I  28246.199219  -3.2430  -6.9233\n",
       "138   Topic5      4.680928  have   6900.304688  -1.9517  -7.0414\n",
       "49    Topic5      4.570027   not   5685.070801  -1.7820  -7.0654\n",
       "79    Topic5      4.333745   can   2098.537109  -0.8385  -7.1185\n",
       "15    Topic5      4.746469     a  26987.019531  -3.3016  -7.0275\n",
       "\n",
       "[410 rows x 6 columns], token_table=       Topic      Freq   Term\n",
       "term                         \n",
       "1530       1  0.758033      !\n",
       "1530       2  0.192833      !\n",
       "1530       3  0.006649      !\n",
       "1530       4  0.039896      !\n",
       "1530       5  0.006649      !\n",
       "...      ...       ...    ...\n",
       "201        4  0.000891   your\n",
       "201        5  0.004455   your\n",
       "28452      5  0.922180    yuk\n",
       "16417      4  0.981737      à\n",
       "30255      4  0.844355  était\n",
       "\n",
       "[693 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 3, 5, 1, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(lda, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the first thing these visualizations tell me is that my model isn't very good. Two of my topics seem to encompass most of the dictionary, at the same time. There are some reasons that could be. First, I may have done something wrong in my preprocessing steps. I suspect this might be the case because of the model predicting my negative fake review would give the place 5 stars. I'm not sure exactly what I've done wrong here, but I am sure there's somewhere I could make a change that would probably improve things a lot.\n",
    "\n",
    "Another big thing that might help, would maybe be adding some topics, allowing them to flesh out and separate a little more. I'm sure there are other parameters I could change as well that might help here, but I'll have to do a little more reading to figure those out. For right now, I'm going to look into the preprocessing more, and try and figure out what, if anything is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "Complete one of more of these to push your score towards a three: \n",
    "* Incorporate named entity recognition into your analysis\n",
    "* Compare vectorization methods in the classification section\n",
    "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
    "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
    "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
